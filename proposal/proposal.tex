\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{natbib}
\usepackage[in]{fullpage}
\usepackage{filecontents}
\usepackage{enumitem}
\title{CS262 Proposal}
\author{Gabe Fierro, Erik Krogen}
\date{February 2016}

\begin{document}

\maketitle

\section{Problem Statement and Motivation}

The context of the Internet of Things has seen an increase in both the number
and capabilities of small, low-powered, constrained devices wanting to interact
with each other and the outside world.  This has raised the question of how to
conduct discovery and communication. Publish-subscribe (\emph{pub-sub}) is
an attractive approach because it decouples publishers from subscribers in
space (communication through a well-known broker helps deal with firewalls and
NATs), and reduces load on popular publishers.

Ensembles of networked ``things'' interacting with dynamic applications require
rich descriptive power to promote discovery across heterogeneous devices and
services, which should be reflected in the syndication mechanism. They also require
the ability to react to changes in the layout or configuration of devices, whether
these changes are generated by the device or by a human administrator. 


There are two dominant ``flavors'' of pub-sub -- topic-based and content-based
-- that traditionally identify
tradeoffs between performance and expressiveness. In topic-based pub-sub
systems, messages are published to logical channels that may be in a flat or
hierarchical namespace, and subscribers identify a name or ``glob'' that
matches topics. The benefits are that matching is typically fast and message
overhead is small, but the expressive power of a ``topic'' is limited.  In
content-based pub-sub, subscribers specify predicates, which act as filters for
incoming messages for publishers. While this scheme has richer descriptive
power, routing on a per-message basis is computationally expensive (reducing
routing efficiency) and can require larger messages from publishers (if
messages must contain descriptive elements for routing).

We propose an alternative pub-sub mechanism, continuous query-based syndication (CQBS),
in which subscriptions are defined by SQL-style queries over devices descriptions. 
Device descriptions contain ``metadata'' defining properties of the device, e.g. location,
units of measure, groupings, etc. that describe the context and configuration of the producer. 
These queries are continuously evaluated to reflect the current configuration of all publishers, enabling
subscribers to always receive messages relevant to their query even as the landscape of
publishers changes.

\section{Goals}

We will focus on the development of a system to meet these requirements: 
\begin{itemize}[noitemsep]
\item Transport should be appropriate for embedded, i.e. memory- and bandwidth-constrained,
devices. As such, messages should be small and require a low processing/memory overhead. 
Likewise, client code should be simple and low-overhead. 
\item Subscriptions must be continually evaluated against metadata to allow for always-up-to-date
information about which subscribers should receive messages from which publishers, even in the
face of changing context and configuration of devices. There may be many active subscribers in the system
at any given time, so the broker must intelligently decide which subscription queries to reevaluate, 
striking a balance between complexity and overhead of heuristics and overhead of reevaluating unchanged queries. 
\item The broker should be able to maintain a high bandwidth and low latency to satisfy the deluge
of IoT devices it may be connected to, and deliver updates in a timely manner to allow applications
to react quickly. 
\end{itemize}

Additionally, we would like to investigate the construction of a distributed broker, reflecting the
distributed nature of IoT devices and applications. This introduces many additional design decisions 
which we will investigate:
\begin{itemize}[noitemsep]
\item What is the most appropriate architecture? Should there be a central metadata repository 
which many brokers communicate with, or should each broker store its own metadata? Should brokers
forward messages to each other, or refer clients to the appropriate broker? 
\item What is the appropriate tradeoff of staleness of metadata vs. latency overhead of metadata updates?
To get completely fresh data at all times, we would require a distributed consensus on each metadata update; 
this would likely be prohibitively expensive. What is the correct consistency model? Is it configurable?
\item How do you account for failure, e.g. network partitions and node failure? What is the correct behavior in 
this type of situation?
\end{itemize}

\section{Prior Work}

Existing pubsub systems include:
\begin{itemize}[noitemsep]
\item Kafka: Topic-based. Very scalable, high-throughput. Topic-based limits generality; there is 
no filterable metadata associated with a topic. Intended for big data-type workloads. 
\item MQTT: Topic-based. Can be adapted for embedded systems (designed for lightweight messages). 
Has ``quality of service'' guarantees that can introduce high overheads. Limited in expressive power. 
\item RabbitMQ/AMQP: Topic-based, or you can subscribe based on key-value pairs in message headers 
(limited content-based pubsub).
\item T Spaces / Java Spaces: Older academic work on tuple spaces, i.e., associative memory for
retrieving data based on a query over collections of tuples used for parallel and distributed computing. 
A precursor to pub-sub, which could be described as content based. 
\end{itemize}

\section{Results \& Evaluation}

We will measure ourselves against existing pub-sub systems on a number of metrics:
\begin{itemize}[noitemsep]
\item Raw throughput and latency metrics for single and distributed brokers under
varying frequency of updates to metadata. 
\item Client implementation metrics: resource requirements, code size, and portability 
\item Generality and usability; how easy would it be to do something like this on existing systems?
What would be the associated performance overheads? This will be likely be qualitative. 
\item Resources required by broker (CPU / memory requirements)
\end{itemize}

We would also like to microbenchmark our broker to determine how well we meet a number of metrics:
\begin{itemize}[noitemsep]
\item How many queries are we unnecessarily reevaluating upon metadata changes?
\item Overhead of locating candidates for reevaluation (introduced forwarding latency, heuristic tradeoff)
\item Overall latency of forwarding messages to subscribers
\end{itemize}

\section{Resources Needed}

We may require a small amount of EC2 credit or other server time but we have this available to us
through other means. We additionally have embedded senors available for evaluation. 

\end{document}
